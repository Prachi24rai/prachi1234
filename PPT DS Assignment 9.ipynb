{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG_odZjhL-Fx"
      },
      "outputs": [],
      "source": [
        "1. What is the difference between a neuron and a neural network?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Neurons take input, process it, and pass it on to other neurons present in the multiple hidden layers of the network, till the processed output reaches the Output Layer. Neural networks are algorithms that can interpret sensory data via machine perception and label or group the raw data"
      ],
      "metadata": {
        "id": "G9ZeCi4WMPBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2. Can you explain the structure and components of a neuron?"
      ],
      "metadata": {
        "id": "yr8KmnCdMPzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A neuron has three main parts: dendrites, an axon, and a cell body or soma (see image below), which can be represented as the branches, roots and trunk of a tree, respectively. A dendrite (tree branch) is where a neuron receives input from other cells."
      ],
      "metadata": {
        "id": "j4S5oUcpMScd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3. Describe the architecture and functioning of a perceptron."
      ],
      "metadata": {
        "id": "QphrAT1jMYPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The perceptron network consists of a single layer of S perceptron neurons connected to R inputs through a set of weights wi,j, as shown below in two forms. As before, the network indices i and j indicate that wi,j is the strength of the connection from the jth input to the ith neuron.\n",
        "\n",
        "A Perceptron is a neural network unit that does certain computations to detect features or business intelligence in the input data. It is a function that maps its input “x,” which is multiplied by the learned weight coefficient, and generates an output value ”f(x)"
      ],
      "metadata": {
        "id": "BNtVRq1LT8Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4. What is the main difference between a perceptron and a multilayer perceptron?"
      ],
      "metadata": {
        "id": "WzMhmCT3ULf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A perceptron is a simple type of neural network that can learn to classify linearly separable patterns. It consists of a single layer of weighted inputs and a binary output. A multi-layer perceptron (MLP) is a more complex type of neural network that can learn to classify non-linearly separable patterns."
      ],
      "metadata": {
        "id": "S_h-69yXULjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5. Explain the concept of forward propagation in a neural network."
      ],
      "metadata": {
        "id": "CX9T0wYGUUI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " Forward propagation is where input data is fed through a network, in a forward direction, to generate an output. The data is accepted by hidden layers and processed, as per the activation function, and moves to the successive layer."
      ],
      "metadata": {
        "id": "kaxfoiOYUZke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6. What is backpropagation, and why is it important in neural network training?"
      ],
      "metadata": {
        "id": "L4hlVmOvUfbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Backpropagation is a process involved in training a neural network. It involves taking the error rate of a forward propagation and feeding this loss backward through the neural network layers to fine-tune the weights. Backpropagation is the essence of neural net training."
      ],
      "metadata": {
        "id": "-QkYKBM4Ufdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7. How does the chain rule relate to backpropagation in neural networks?"
      ],
      "metadata": {
        "id": "zrmuCTP-UfjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The chain rule can be generalised to multivariate functions, and represented by a tree diagram. The chain rule is applied extensively by the backpropagation algorithm in order to calculate the error gradient of the loss function with respect to each weight."
      ],
      "metadata": {
        "id": "NTBi1V1WUfob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8. What are loss functions, and what role do they play in neural networks?"
      ],
      "metadata": {
        "id": "TnbWy3rnU2J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A loss function is a function that compares the target and predicted output values; measures how well the neural network models the training data. When training, we aim to minimize this loss between the predicted and target outputs."
      ],
      "metadata": {
        "id": "Rj95XJX1U2MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9. Can you give examples of different types of loss functions used in neural networks?"
      ],
      "metadata": {
        "id": "A5YmBhcZU2On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Some common loss functions in neural networks used for regression tasks include mean squared error (MSE) loss, mean squared logarithmic error (MSLE) loss, and mean absolute error (MAE) loss."
      ],
      "metadata": {
        "id": "ft0F8HWAU2RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10. Discuss the purpose and functioning of optimizers in neural networks."
      ],
      "metadata": {
        "id": "BDLxQZxxU2Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "An optimizer is an algorithm or function that adapts the neural network's attributes, like learning rate and weights. Hence, it assists in improving the accuracy and reduces the total loss. But it is a daunting task to choose the appropriate weights for the model."
      ],
      "metadata": {
        "id": "JmdiXdEVU2WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "11. What is the exploding gradient problem, and how can it be mitigated?"
      ],
      "metadata": {
        "id": "A-U2BTgIU2YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "These gradients are used to update the weights. If the gradients are large, the multiplication of these gradients will become huge over time. This results in the model being unable to learn and its behavior becomes unstable. This problem is called the exploding gradient problem.\n",
        "\n",
        "In general, exploding gradients can be avoided by carefully configuring the network model, such as using a small learning rate, scaling the target variables, and using a standard loss function. However, in recurrent networks with a large number of input time steps, exploding gradients may still be an issue."
      ],
      "metadata": {
        "id": "-ws1gFr3U2bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "12. Explain the concept of the vanishing gradient problem and its impact on neural network training."
      ],
      "metadata": {
        "id": "SU-kjhssVkaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vanishing gradient problem is a phenomenon that occurs during the training of deep neural networks, where the gradients that are used to update the network become extremely small or \"vanish\" as they are backpropogated from the output layers to the earlier layers.\n",
        "One of the newest and most effective ways to resolve the vanishing gradient problem is with residual neural networks, or ResNets (not to be confused with recurrent neural networks). ResNets refer to neural networks where skip connections or residual connections are part of the network architecture.\n"
      ],
      "metadata": {
        "id": "dZtC8d7KVkcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13. How does regularization help in preventing overfitting in neural networks?"
      ],
      "metadata": {
        "id": "0zmQlCcgVke6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regularization comes into play and shrinks the learned estimates towards zero. In other words, it tunes the loss function by adding a penalty term, that prevents excessive fluctuation of the coefficients. Thereby, reducing the chances of overfitting"
      ],
      "metadata": {
        "id": "jurVt7y7Vkhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "14. Describe the concept of normalization in the context of neural networks.\n"
      ],
      "metadata": {
        "id": "qXdB5ltEWQ9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Among the best practices for training a Neural Network is to normalize your data to obtain a mean close to 0. Normalizing the data generally speeds up learning and leads to faster convergence."
      ],
      "metadata": {
        "id": "T28ygBKRWREF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "15. What are the commonly used activation functions in neural networks?"
      ],
      "metadata": {
        "id": "yLlOwQEpWRGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "What is a Neural Network Activation Function? An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuron's input to the network is important or not in the process of prediction using simpler mathematical operations."
      ],
      "metadata": {
        "id": "WdidcGznWRJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "16. Explain the concept of batch normalization and its advantages."
      ],
      "metadata": {
        "id": "2ID8MxSwWRLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Batch normalization is a technique to standardize the inputs to a network, applied to ether the activations of a prior layer or inputs directly. Batch normalization accelerates training, in some cases by halving the epochs or better, and provides some regularization, reducing generalization error."
      ],
      "metadata": {
        "id": "xAwv2m90WROm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "17. Discuss the concept of weight initialization in neural networks and its importance."
      ],
      "metadata": {
        "id": "ZCcauq0bWRSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "While building and training neural networks, it is crucial to initialize the weights appropriately to ensure a model with high accuracy. If the weights are not correctly initialized, it may give rise to the Vanishing Gradient problem or the Exploding Gradient problem."
      ],
      "metadata": {
        "id": "SK52jPIbVkk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "18. Can you explain the role of momentum in optimization algorithms for neural networks?\n"
      ],
      "metadata": {
        "id": "-2wISIBKU2lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Neural network momentum is a simple technique that often improves both training speed and accuracy. Training a neural network is the process of finding values for the weights and biases so that for a given set of input values, the computed output values closely match the known, correct, target values.\n",
        "\n",
        "Momentum is a strategy for accelerating the convergence of the optimization process by including a momentum element in the update rule. This momentum factor assists the optimizer in continuing to go in the same direction even if the gradient changes direction or becomes zero."
      ],
      "metadata": {
        "id": "H-SfgZrRXI0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "19. What is the difference between L1 and L2 regularization in neural networks?"
      ],
      "metadata": {
        "id": "c4g18B8eXI2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The first, L1 regularization, uses a penalty term which encourages the sum of the abso- lute values of the parameters to be small. The second, L2 regularization, encourages the sum of the squares of the parameters to be small."
      ],
      "metadata": {
        "id": "n3QolOtSXI4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "20. How can early stopping be used as a regularization technique in neural networks?"
      ],
      "metadata": {
        "id": "jz0k2llBXI8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Regularization by early stopping can be done either by dividing the dataset into training and test sets and then using cross-validation on the training set or by dividing the dataset into training, validation and test sets, in which case cross-validation, is not required."
      ],
      "metadata": {
        "id": "qWvP5jZaXI-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "21. Describe the concept and application of dropout regularization in neural networks."
      ],
      "metadata": {
        "id": "0QZbNkobXJCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dropouts can be used with most types of neural networks. It is a great tool to reduce overfitting in a model. It is far better than the available regularisation methods and can also be combined with max-norm normalisation which provides a significant boost over just using dropout."
      ],
      "metadata": {
        "id": "UjMXs1ygXJM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "22. Explain the importance of learning rate in training neural networks."
      ],
      "metadata": {
        "id": "qbjrSR2uXJXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "In neural network models, the learning rate is a crucial hyperparameter that regulates the magnitude of weight updates applied during training. It is crucial in influencing the rate of convergence and the caliber of a model's answer."
      ],
      "metadata": {
        "id": "w7TE2qdsYOj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "23. What are the challenges associated with training deep neural networks?"
      ],
      "metadata": {
        "id": "wPrMnoIsYOmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Deep learning has several advantages over traditional machine learning methods, including automatic feature learning, handling large and complex data, improved performance, handling non-linear relationships, handling structured and unstructured data, predictive modeling, handling missing data, handling sequential data,"
      ],
      "metadata": {
        "id": "5VDZFctAYOom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "24. How does a convolutional neural network (CNN) differ from a regular neural network?"
      ],
      "metadata": {
        "id": "W1uyv34oYOrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " main differences between convolutional and regular neural networks. To conclude, the main difference is that CNN uses convolution operation to process the data, which has some benefits for working with images. In that way, CNNs reduce the number of parameters in the network"
      ],
      "metadata": {
        "id": "FhC4aheLYOuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "25. Can you explain the purpose and functioning of pooling layers in CNNs?"
      ],
      "metadata": {
        "id": "bufHfZkXYOxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer"
      ],
      "metadata": {
        "id": "zAIx5JTdYO0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "26. What is a recurrent neural network (RNN), and what are its applications?"
      ],
      "metadata": {
        "id": "QCde25HUYO3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN is used in popular products such as Google's voice search and Apple's Siri to process user input and predict the output. Recurrent Neural Networks can be concluded to be a versatile tool that can be used in a variety of situations. They are used in a number of methods for language modeling and text generation."
      ],
      "metadata": {
        "id": "mbtmLbVzYO6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "27. Describe the concept and benefits of long short-term memory (LSTM) networks."
      ],
      "metadata": {
        "id": "PiTupG10TM7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Long short-term memory (LSTM) network is a recurrent neural network (RNN), aimed to deal with the vanishing gradient problem present in traditional RNNs. Its relative insensitivity to gap length is its advantage over other RNNs, hidden Markov models and other sequence learning methods."
      ],
      "metadata": {
        "id": "umByGxNdTM92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "28. What are generative adversarial networks (GANs), and how do they work?"
      ],
      "metadata": {
        "id": "mQ-tc6V8TNAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A generative adversarial network (GAN) has two parts: The generator learns to generate plausible data. The generated instances become negative training examples for the discriminator. The discriminator learns to distinguish the generator's fake data from real data."
      ],
      "metadata": {
        "id": "fSYfaOKZTNDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "29. Can you explain the purpose and functioning of autoencoder neural networks?"
      ],
      "metadata": {
        "id": "AR7pPDB5TNGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoders are used to help reduce the noise in data. Through the process of compressing input data, encoding it, and then reconstructing it as an output, autoencoders allow you to reduce dimensionality and focus only on areas of real value.\n",
        "\n",
        "\n",
        "The cost function is typically a combination of a reconstruction loss and a sparsity penalty. The reconstruction loss is a measure of the difference between the input data and the output of the autoencoder. The most commonly used reconstruction loss is the mean squared error (MSE), which is defined as"
      ],
      "metadata": {
        "id": "ogQDHu7nTNJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "30. Discuss the concept and applications of self-organizing maps (SOMs) in neural networks."
      ],
      "metadata": {
        "id": "UDhSE1ssTNLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The concept of a self-organizing map, or SOM, was first put forth by Kohonen. It is a way to reduce data dimensions since it is an unsupervised neural network that is trained using unsupervised learning techniques to build a low-dimensional, discretized representation from the input space of the training samples.\n",
        "\n",
        "One of the earliest and well known applications of the SOM is the phonetic typewriter of Kohonen. It is set in the field of speech recognition, and the problem is to classify phonemes in real time so that they could be used to drive a typewriter from dictation."
      ],
      "metadata": {
        "id": "_gW6_QxYTNOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "31. How can neural networks be used for regression tasks?"
      ],
      "metadata": {
        "id": "cC5fk96UTNRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The input features are passed through the input layer of the DNN and then processed by the hidden layers, which use non-linear activation functions to learn complex relationships in the data."
      ],
      "metadata": {
        "id": "UU0I_gZmTNVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "32. What are the challenges in training neural networks with large datasets?"
      ],
      "metadata": {
        "id": "reyiNUKtVDWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Training a neural network involves using an optimization algorithm to find a set of weights to best map inputs to outputs. The problem is hard, not least because the error surface is non-convex and contains local minima, flat spots, and is highly multidimensional."
      ],
      "metadata": {
        "id": "cU4IzXbTVDZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "33. Explain the concept of transfer learning in neural networks and its benefits."
      ],
      "metadata": {
        "id": "dCjTotOIVDb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer learning is a machine learning method where we reuse a pre-trained model as the starting point for a model on a new task. To put it simply—a model trained on one task is repurposed on a second, related task as an optimization that allows rapid progress when modeling the second task\n",
        "\n",
        "If learning is effectively transferred into the workplace and used, there are lots of potential benefits to be had:\n",
        "Improved productivity.\n",
        "Higher staff engagement rates.\n",
        "Reduced staff attrition.\n",
        "Improved customer service.\n",
        "Higher revenues and profits.\n",
        "Reduced costs.\n",
        "Increased morale.\n",
        "Better motivation."
      ],
      "metadata": {
        "id": "pJ2VGqM7VDek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "34. How can neural networks be used for anomaly detection tasks?"
      ],
      "metadata": {
        "id": "EwP19mT7VDhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Network behavior anomaly detection uses artificial intelligence (AI) and machine learning (ML) to detect hidden threats in those parts of network infrastructure that other security tools cannot reach and then notifies network teams."
      ],
      "metadata": {
        "id": "GNIxH42NVDj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "35. Discuss the concept of model interpretability in neural networks."
      ],
      "metadata": {
        "id": "AGzxYnEWVDmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A model with high accuracy is what we usually call a good model, it learned the relationship between the inputs X and outputs y well. If a model has high interpretability or explainability, we understand how the model makes a prediction and how we can influence this prediction by changing input features."
      ],
      "metadata": {
        "id": "fPL3FloyVDo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "36. What are the advantages and disadvantages of deep learning compared to traditional machine learning algorithms?"
      ],
      "metadata": {
        "id": "IgZ7m-NOVDsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The biggest advantage Deep Learning algorithms as discussed before are that they try to learn high-level features from data in an incremental manner. This eliminates the need of domain expertise and hard core feature extraction."
      ],
      "metadata": {
        "id": "8cNRtqtRYbxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "37. Can you explain the concept of ensemble learning in the context of neural networks?"
      ],
      "metadata": {
        "id": "bDIz645AYb0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ensemble learning is the process by which multiple models, such as classifiers or experts, are strategically generated and combined to solve a particular computational intelligence problem. Ensemble learning is primarily used to improve the (classification, prediction, function approximation, etc.)"
      ],
      "metadata": {
        "id": "NNymrdRyYt0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "38. How can neural networks be used for natural language processing (NLP) tasks?"
      ],
      "metadata": {
        "id": "rbWnHVKPYt2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "How does natural language processing work? NLP enables computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand."
      ],
      "metadata": {
        "id": "BdWXkJ5aYt5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "39. Discuss the concept and applications of self-supervised learning in neural networks."
      ],
      "metadata": {
        "id": "fGJ_B6iUYt76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Face Detection\n",
        "\n",
        "This is one of the most common applications of SSL. Self-supervised learning is used in matching on screen faces with the input fed data. It is used for security purposes in mobile phones."
      ],
      "metadata": {
        "id": "wwSt5v3FYt-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "40. What are the challenges in training neural networks with imbalanced datasets?"
      ],
      "metadata": {
        "id": "AiaEHgcVYuB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Imbalanced classification is specifically hard because of the severely skewed class distribution and the unequal misclassification costs. The difficulty of imbalanced classification is compounded by properties such as dataset size, label noise, and data distribution.\n",
        "\n",
        "Training a neural network involves using an optimization algorithm to find a set of weights to best map inputs to outputs. The problem is hard, not least because the error surface is non-convex and contains local minima, flat spots, and is highly multidimensional."
      ],
      "metadata": {
        "id": "NGarY83eZbMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "41. Explain the concept of adversarial attacks on neural networks and methods to mitigate them."
      ],
      "metadata": {
        "id": "vGYfN_qNZbPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "An adversarial attack is a method of making small modifications to the objects in such a way that the machine learning model begins to misclassify them. Neural networks (NN) are known to be vulnerable to such attacks. Research of adversarial methods historically started in the sphere of image recognition."
      ],
      "metadata": {
        "id": "xs_E7aOoZbSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "42. Can you discuss the trade-off between model complexity and generalization performance in neural networks?\n"
      ],
      "metadata": {
        "id": "cmRgIbqDZbUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generalization refers to your model's ability to adapt properly to new, previously unseen data, drawn from the same distribution as the one used to create the model. Estimated Time: 5 minutes Learning Objectives. Develop intuition about overfitting. Determine whether a model is good or not\n",
        "\n",
        "Model selection is the process of selecting one final machine learning model from among a collection of candidate machine learning models for a training dataset. Model selection is a process that can be applied both across different types of models (e.g. logistic regression, SVM, KNN, etc.)"
      ],
      "metadata": {
        "id": "rrooxq6yZbXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "43. What are some techniques for handling missing data in neural networks?"
      ],
      "metadata": {
        "id": "BMxNLqVgaGzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Missing data can frequently occur in a longitudinal data analysis. In the literature, many methods have been proposed to handle such an issue. Complete case (CC), mean substitution (MS), last observation carried forward (LOCF), and multiple imputation (MI) are the four most frequently used methods in practice."
      ],
      "metadata": {
        "id": "CPkMQvFGaG15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "44. Explain the concept and benefits of interpretability techniques like SHAP values and LIME in neural networks."
      ],
      "metadata": {
        "id": "mTlwAXdOaG4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LIME generates a perturbed dataset to fit an explainable model, while SHAP requires an entire sample to calculate SHAP values. This means that LIME requires only one observation, while SHAP requires multiple observations.\n",
        "\n",
        " interpretability can lead to better decision-making because when a model is tested in the real world, those who developed it can observe its strengths and weaknesses. The chapter provides a plausible example of this, where a self-driving car mistakes snow for pavement and crashes into a cliff.\n",
        "\n",
        " Interpretability allows us to understand what exactly a model is learning, what other information the model has to offer, and the justifications behind its decisions, and evaluate all of these in the context of the real-world problem we are trying to solve."
      ],
      "metadata": {
        "id": "WPVoxUolaG7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "45. How can neural networks be deployed on edge devices for real-time inference?"
      ],
      "metadata": {
        "id": "kTLm2m-4aG9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "While the integration of fourth-generation (4G) networks with Edge Computing technologies would anticipate the improvements foreseen by the coming of 5G, as well as smoothen the transition to the new technology, 4G does not natively support Edge Computing."
      ],
      "metadata": {
        "id": "-KW8UANBaHBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "46. Discuss the considerations and challenges in scaling neural network training on distributed systems."
      ],
      "metadata": {
        "id": "9UP17KGPZbaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Training a neural network involves using an optimization algorithm to find a set of weights to best map inputs to outputs. The problem is hard, not least because the error surface is non-convex and contains local minima, flat spots, and is highly multidimensional.\n"
      ],
      "metadata": {
        "id": "xY5vNjUzZbdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "47. What are the ethical implications of using neural networks in decision-making systems?"
      ],
      "metadata": {
        "id": "4knPfC_KblTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ethical decision-making is based on core character values like trustworthiness, respect, responsibility, fairness, caring, and good citizenship. Ethical decisions generate ethical behaviors and provide a foundation for good business practices. See a model for making ethical decisions."
      ],
      "metadata": {
        "id": "LmKZ9XGPblV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "48. Can you explain the concept and applications of reinforcement learning in neural networks?"
      ],
      "metadata": {
        "id": "UAsT_qRDblYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Reinforcement learning is an area of Machine Learning. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation.\n",
        "\n",
        "\n",
        "Reinforcement Learning is a trending data-driven approach for adaptive traffic signal control. These models are trained with the objective of learning a policy using a value function that optimally controls the traffic light based on the current status of the traffic.\n",
        "\n",
        "Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward."
      ],
      "metadata": {
        "id": "9-dHTlvHbla6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "49. Discuss the impact\n",
        "\n",
        " of batch size in training neural networks.\n"
      ],
      "metadata": {
        "id": "iRzjYoP_blda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The batch size affects some indicators such as overall training time, training time per epoch, quality of the model, and similar. Usually, we chose the batch size as a power of two, in the range between 16 and 512. But generally, the size of 32 is a rule of thumb and a good initial choice.16-Mar-2023"
      ],
      "metadata": {
        "id": "-VCleLfablgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "50. What are the current limitations of neural networks and areas for future research?"
      ],
      "metadata": {
        "id": "EKnf55JBbljN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Neural networks are vulnerable to subtle perturbations or modifications of the input data, which can cause them to produce incorrect or misleading outputs. For example, adding a small amount of noise or changing a few pixels in an image can fool a neural network into misclassifying it as a different object."
      ],
      "metadata": {
        "id": "C_euAROCblmo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}